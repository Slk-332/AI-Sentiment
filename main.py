import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from google import genai
import warnings

warnings.filterwarnings("ignore")

MODEL_NAME = "cardiffnlp/twitter-xlm-roberta-base-sentiment"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

label_map = {
    0: "Negative",
    1: "Neutral",
    2: "Positive"
}

API_KEY = "AIzaSyDzkAEXeJ7zUbVIjIjf4tBfebGGTt-_RgE"
client = genai.Client(api_key=API_KEY)

def predict_sentiment(text):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
    inputs = tokenizer(str(text), return_tensors="pt", truncation=True, max_length=512, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    return label_map[torch.argmax(outputs.logits, dim=1).item()]

def generate_executive_summary(df):
    # 1. ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Prompt
   # 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç NameError: total, pos, etc.)
    total = len(df)
    counts = df["sentiment"].value_counts()
    pos = counts.get("Positive", 0)
    neu = counts.get("Neutral", 0)
    neg = counts.get("Negative", 0)

    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢ (all_text)
    # ‡∏î‡∏∂‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß 30 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ AI ‡∏î‡∏π‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
    all_samples = df["review"].astype(str).head(30).tolist()
    all_text = "\n".join([f"- {s}" for s in all_samples])
    
    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö (neg_text)
    neg_samples = df[df.sentiment == "Negative"]["review"].astype(str).head(15).tolist()
    neg_text = "\n".join([f"- {s}" for s in neg_samples])
    
    if not neg_samples and not all_samples:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"

    # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {total} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

[‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö]
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
- ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å: {pos} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
- ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á: {neu} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
- ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö: {neg} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

[‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå]
{all_text}

---
‡∏à‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
1. ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
2. ‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢ (Common Themes): ‡∏£‡∏∞‡∏ö‡∏∏ Keyword ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏ã‡πâ‡∏≥‡πÜ (‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏Ñ‡∏≤, ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£, ‡∏Å‡∏≤‡∏£‡∏Ç‡∏ô‡∏™‡πà‡∏á)
3. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å 3 ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô: ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô
4. ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå 1 ‡∏Ç‡πâ‡∏≠: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô

(‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÜ ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö)
"""

    try:
        # ‡πÉ‡∏ä‡πâ‡∏£‡∏∏‡πà‡∏ô 2.0-flash ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Quota (429)
        response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Gemini Error: {str(e)}"

def analyze():
    path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
    if not path:
        return

    df = pd.read_csv(path)
    if "review" not in df.columns:
        messagebox.showerror("Error", "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠ review")
        return

    df["sentiment"] = df["review"].astype(str).apply(predict_sentiment)
    # ===== Summary =====
    summary_text.delete("1.0", tk.END)
    # call the actual summary function (was generate_summary -> NameError)
    summary_text.insert(tk.END, generate_executive_summary(df))

# ...existing code...

# ---------------- UI ----------------
root = tk.Tk()
root.title("Thai Sentiment Analysis")
root.geometry("1000x600")
root.configure(bg="#f4f6f9")

style = ttk.Style()
style.theme_use("default")
style.configure("Card.TFrame", background="white", relief="ridge", padding=15)
style.configure("Title.TLabel", font=("Segoe UI", 16, "bold"), background="#f4f6f9")
style.configure("Big.TLabel", font=("Segoe UI", 20, "bold"))
style.configure("Sub.TLabel", font=("Segoe UI", 11), foreground="#555")

# ================== HEADER ==================
ttk.Label(root, text="Thai Sentiment Analysis Dashboard", style="Title.TLabel").pack(pady=10)

ttk.Button(root, text="üìÇ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", command=lambda: analyze()).pack(pady=5)

# ================== SUMMARY ==================
summary = ttk.Frame(root)
summary.pack(fill="x", padx=40, pady=10)

def summary_card(parent, emoji, title, color):
    frame = ttk.Frame(parent, style="Card.TFrame")
    tk.Label(frame, text=emoji, font=("Segoe UI Emoji", 40), bg="white").pack()
    tk.Label(frame, text=title, font=("Segoe UI", 14, "bold"), bg="white").pack()
    lbl_percent = tk.Label(frame, text="0%", font=("Segoe UI", 30, "bold"), fg=color, bg="white")
    lbl_percent.pack()
    return frame, lbl_percent

card_pos, lbl_pos = summary_card(summary, "üòä", "Positive", "#2ca02c")
card_neu, lbl_neu = summary_card(summary, "üòê", "Neutral", "#7f7f7f")
card_neg, lbl_neg = summary_card(summary, "üò†", "Negative", "#d62728")

card_pos.pack(side="left", expand=True, fill="both", padx=15)
card_neu.pack(side="left", expand=True, fill="both", padx=15)
card_neg.pack(side="left", expand=True, fill="both", padx=15)

# Executive Summary Section (‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏ï‡∏≤‡∏°‡∏à‡∏≠)
tk.Label(root, text="Auto Executive Summary (Gemini 2.0 AI Analysis)", font=("Segoe UI", 14, "bold"), bg="#f4f6f9").pack(anchor="w", padx=45, pady=(20, 5))
summary_text = tk.Text(root, height=12, wrap="word", bg="white", font=("Tahoma", 11), padx=20, pady=20, relief="flat")
summary_text.pack(fill="both", expand=False, padx=40, pady=10)

# ================== REVIEWS ==================
reviews_frame = ttk.Frame(root)
reviews_frame.pack(fill="both", expand=True, padx=20, pady=10)

def review_column(parent, title):
    frame = ttk.Frame(parent, style="Card.TFrame")
    tk.Label(frame, text=title, font=("Segoe UI", 12, "bold"), bg="white").pack()
    scrollbar = ttk.Scrollbar(frame)
    scrollbar.pack(side="right", fill="y")
    text = tk.Text(frame, height=15, wrap="word", yscrollcommand=scrollbar.set)
    text.pack(fill="both", expand=True)
    scrollbar.config(command=text.yview)
    return frame, text

frame_p, text_p = review_column(reviews_frame, "Positive Reviews")
frame_n, text_n = review_column(reviews_frame, "Neutral Reviews")
frame_ng, text_ng = review_column(reviews_frame, "Negative Reviews")

reviews_frame.columnconfigure((0,1,2), weight=1)

frame_p.grid(row=0, column=0, sticky="nsew", padx=5)
frame_n.grid(row=0, column=1, sticky="nsew", padx=5)
frame_ng.grid(row=0, column=2, sticky="nsew", padx=5)


# ================== LOGIC ==================
def analyze():
    path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
    if not path:
        return

    df = pd.read_csv(path)
    if "review" not in df.columns:
        messagebox.showerror("Error", "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠ review")
        return

    # 1. Run Sentiment Analysis
    df["sentiment"] = df["review"].astype(str).apply(predict_sentiment)

    # 2. Update Executive Summary
    summary_text.delete("1.0", tk.END)
    summary_text.insert(tk.END, generate_executive_summary(df))

    # 3. Categorize Reviews
    pos_list = df[df.sentiment == "Positive"]["review"].tolist()
    neu_list = df[df.sentiment == "Neutral"]["review"].tolist()
    neg_list = df[df.sentiment == "Negative"]["review"].tolist()

    # 4. Update Statistic Cards
    total = len(df)
    lbl_pos.config(text=f"{len(pos_list)/total*100:.1f}%")
    lbl_neu.config(text=f"{len(neu_list)/total*100:.1f}%")
    lbl_neg.config(text=f"{len(neg_list)/total*100:.1f}%")

    # 5. Update Review Text Boxes (using the text_p, text_n, text_ng names)
    for t in (text_p, text_n, text_ng):
        t.delete("1.0", tk.END)

    for i, r in enumerate(pos_list, 1):
        text_p.insert(tk.END, f"{i}. {r}\n\n")
    for i, r in enumerate(neu_list, 1):
        text_n.insert(tk.END, f"{i}. {r}\n\n")
    for i, r in enumerate(neg_list, 1):
        text_ng.insert(tk.END, f"{i}. {r}\n\n")

    # 6. Show Visualization
    plt.figure(figsize=(5, 5))
    df["sentiment"].value_counts().plot(kind="pie", autopct="%.1f%%", title="Sentiment Distribution")
    plt.ylabel("")
    plt.show()

root.mainloop()